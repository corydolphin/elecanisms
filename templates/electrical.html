{% extends "base.html" %}
{% block maincontent %}
<div class="row">

    <!-- Main Blog Content -->
    <div class="large-10 columns" role="content">

      <article>

        <h3><a href="#">System Overview</a></h3>
        <div class="row">
          <div class="large-6 columns">
            <p>
              Above is a system diagram describing the main parts of the follower. The Kinect sensor observes the environment, and returns a point cloud describing its surroundings. This data is used in a control algorithm run on the PC, which sends motor commands to the PIC24. The PIC modulates 2 PWM signals (one for each motor) and outputs them to the 2 motor controllers. 
              These H-bridge motor controllers control the flow of current from the battery to the motors, driving the treads. 
            </p>
         </div>
          <div class="large-6 columns">
            <img src="./static/img/image04.png">
          </div>
        </div>
      </article>

      <article>

        <h3><a href="#">Sensing</a></h3>
        <div class="row">
          <div class="large-8 columns">

            <h4><a href="#">The first approach</a></h4>
            <p>
              Our first approach to sensing onboard the tankbot was to use a Wiimote camera in conjunction with a Sharp IR proximity sensor. The Wiimote camera, when combined with an IR filter, gives us the location of an IR beacon carried by the user. We designed a custom PCB which allowed us to reliably read data from the camera over I2C.
              Since the Wiimote camera lacked distance sensing ability, we used a Sharp IR proximity sensor for basic obstacle avoidance.
            </p>
            <p>
            The benefit of this approach was that both sensors could be run off the PIC24, and neither required more power than the PIC could output. Both sensors were also very small which allowed for more carrying capacity. However, this  approach was limited because the Wiimote did not have depth sensing. This made it impossible for the robot to follow a user within a consistent threshold.
            </p>
            <h4><a href="#">Second iteration</a></h4>
            <p>
            For our second iteration, we opted for a more robust sensing system. We used a Microsoft Kinect, which eliminated the need for the user to hold an IR beacon. The switch to the Kinect also added depth sensing, which allowed for better following behavior. It could also be used for obstacle avoidance, which eliminated the need for the added IR sensor.
            </p>
          <p>
          Although this new approach worked better than the Wiimote plan, there were several tradeoffs from adding a Kinect. The Kinect required using a laptop PC instead of a microcontroller, which took up space and limited the battery life of the robot. The Kinect also required a 12V supply, which we hoped to supply with the main 12V battery. However, the main battery voltage was too inconsistent to run the Kinect, so we needed to add a separate battery for the Kinect.
          </p>
         </div>
          <div class="large-4 columns">
            <img src="./static/img/image12.png">
            <img src="./static/img/image15.png">
          </div>
        </div>
      </article>
    </div>
    <!-- End Main Content -->
  </div>

{% endblock %}